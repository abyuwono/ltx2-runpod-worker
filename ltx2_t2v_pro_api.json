{
  "5232": {
    "class_type": "EmptyImage",
    "inputs": {
      "width": 1920,
      "height": 1088,
      "batch_size": 1,
      "color": 0
    },
    "_meta": {
      "title": "EmptyImage"
    }
  },
  "5235": {
    "class_type": "CM_FloatToInt",
    "inputs": {
      "a": [
        "5236",
        0
      ]
    },
    "_meta": {
      "title": "Frame Rate"
    }
  },
  "5236": {
    "class_type": "PrimitiveFloat",
    "inputs": {
      "value": 24
    },
    "_meta": {
      "title": "Frame Rate"
    }
  },
  "5220": {
    "class_type": "CheckpointLoaderSimple",
    "inputs": {
      "ckpt_name": "ltx-2-19b-dev.safetensors"
    },
    "_meta": {
      "title": "CheckpointLoaderSimple"
    }
  },
  "5219": {
    "class_type": "LTXVAudioVAELoader",
    "inputs": {
      "model_name": "ltx-2-19b-dev.safetensors"
    },
    "_meta": {
      "title": "LTXVAudioVAELoader"
    }
  },
  "5075": {
    "class_type": "SaveVideo",
    "inputs": {
      "filename_prefix": "video/LTX-2",
      "format": "auto",
      "codec": "auto",
      "video": [
        "5223",
        0
      ]
    },
    "_meta": {
      "title": "SaveVideo"
    }
  },
  "5229": {
    "class_type": "LTXVConditioning",
    "inputs": {
      "steps": 25,
      "positive": [
        "5228",
        0
      ],
      "negative": [
        "5226",
        0
      ],
      "frame_rate": [
        "5236",
        0
      ]
    },
    "_meta": {
      "title": "LTXVConditioning"
    }
  },
  "5228": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "text": [
        "5227",
        0
      ],
      "clip": [
        "5218",
        0
      ]
    },
    "_meta": {
      "title": "Enhanced Prompt (Positive)"
    }
  },
  "5221": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "lora_name": "your_camera_lora.safetensors",
      "strength_model": 1,
      "model": [
        "5216",
        0
      ]
    },
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "5222": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "lora_name": "your_camera_lora.safetensors",
      "strength_model": 1,
      "model": [
        "5220",
        0
      ]
    },
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "5226": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "text": "blurry, low quality, still frame, frames, watermark, overlay, titles, has blurbox, has subtitles",
      "clip": [
        "5218",
        0
      ]
    },
    "_meta": {
      "title": "CLIPTextEncode"
    }
  },
  "5270": {
    "class_type": "LatentUpscaleModelLoader",
    "inputs": {
      "model_name": "ltx-2-spatial-upscaler-x2-1.0.safetensors"
    },
    "_meta": {
      "title": "LatentUpscaleModelLoader"
    }
  },
  "5273": {
    "class_type": "MarkdownNote",
    "inputs": {},
    "_meta": {
      "title": "Video Size"
    }
  },
  "5274": {
    "class_type": "MarkdownNote",
    "inputs": {},
    "_meta": {
      "title": "LoRA"
    }
  },
  "5227": {
    "class_type": "LTXVGemmaEnhancePrompt",
    "inputs": {
      "user_prompt": "",
      "system_prompt": "You are a Creative Assistant. Given a user's raw input prompt describing a scene or concept, expand it into a detailed video generation prompt with specific visuals and integrated audio to guide a text-to-video model.\n\n#### Guidelines\n- Strictly follow all aspects of the user's raw input: include every element requested (style, visuals, motions, actions, camera movement, audio).\n    - If the input is vague, invent concrete details: lighting, textures, materials, scene settings, etc.\n        - For characters: describe gender, clothing, hair, expressions. DO NOT invent unrequested characters.\n- Use active language: present-progressive verbs (\"is walking,\" \"speaking\"). If no action specified, describe natural movements.\n- Maintain chronological flow: use temporal connectors (\"as,\" \"then,\" \"while\").\n- Audio layer: Describe complete soundscape (background audio, ambient sounds, SFX, speech/music when requested). Integrate sounds chronologically alongside actions. Be specific (e.g., \"soft footsteps on tile\"), not vague (e.g., \"ambient sound is present\").\n- Speech (only when requested): \n    - For ANY speech-related input (talking, conversation, singing, etc.), ALWAYS include exact words in quotes with voice characteristics (e.g., \"The man says in an excited voice: 'You won't believe what I just saw!'\").\n    - Specify language if not English and accent if relevant.\n- Style: Include visual style at the beginning: \"Style: <style>, <rest of prompt>.\" Default to cinematic-realistic if unspecified. Omit if unclear.\n- Visual and audio only: NO non-visual/auditory senses (smell, taste, touch).\n- Restrained language: Avoid dramatic/exaggerated terms. Use mild, natural phrasing.\n    - Colors: Use plain terms (\"red dress\"), not intensified (\"vibrant blue,\" \"bright red\").\n    - Lighting: Use neutral descriptions (\"soft overhead light\"), not harsh (\"blinding light\").\n    - Facial features: Use delicate modifiers for subtle features (i.e., \"subtle freckles\").\n\n#### Important notes: \n- Analyze the user's raw input carefully. In cases of FPV or POV, exclude the description of the subject whose POV is requested.\n- Camera motion: DO NOT invent camera motion unless requested by the user.\n- Speech: DO NOT modify user-provided character dialogue unless it's a typo.\n- No timestamps or cuts: DO NOT use timestamps or describe scene cuts unless explicitly requested.\n- Format: DO NOT use phrases like \"The scene opens with...\". Start directly with Style (optional) and chronological scene description.\n- Format: DO NOT start your response with special characters.\n- DO NOT invent dialogue unless the user mentions speech/talking/singing/conversation.\n- If the user's raw input prompt is highly detailed, chronological and in the requested format: DO NOT make major edits or introduce new elements. Add/enhance audio descriptions if missing.\n\n#### Output Format (Strict):\n- Single continuous paragraph in natural language (English).\n- NO titles, headings, prefaces, code fences, or Markdown.\n- If unsafe/invalid, return original user prompt. Never ask questions or clarifications.\n\nYour output quality is CRITICAL. Generate visually rich, dynamic prompts with integrated audio for high-quality video generation.\n\n#### Example\nInput: \"A woman at a coffee shop talking on the phone\"\nOutput:\nStyle: realistic with cinematic lighting. In a medium close-up, a woman in her early 30s with shoulder-length brown hair sits at a small wooden table by the window. She wears a cream-colored turtleneck sweater, holding a white ceramic coffee cup in one hand and a smartphone to her ear with the other. Ambient cafe sounds fill the space\u2014espresso machine hiss, quiet conversations, gentle clinking of cups. The woman listens intently, nodding slightly, then takes a sip of her coffee and sets it down with a soft clink. Her face brightens into a warm smile as she speaks in a clear, friendly voice, 'That sounds perfect! I'd love to meet up this weekend. How about Saturday afternoon?' She laughs softly\u2014a genuine chuckle\u2014and shifts in her chair. Behind her, other patrons move subtly in and out of focus. 'Great, I'll see you then,' she concludes cheerfully, lowering the phone.",
      "max_new_tokens": 512,
      "do_sample": true,
      "seed": 2793143611,
      "control_after_generate": "randomize",
      "clip": [
        "5218",
        0
      ],
      "prompt": [
        "5225",
        0
      ]
    },
    "_meta": {
      "title": "Enhancer"
    }
  },
  "5225": {
    "class_type": "PrimitiveStringMultiline",
    "inputs": {
      "value": "cinematic drama movie scene shows a closeup of a blonde woman wearing a red sweater hanging out of the open door of a moving train, looking outside and smiling. the camera is fixed to the train's side as the train moves forward on the track. the woman seems excited and says: \" I think we're almost there!\". we hear the train's engine in the background. then, a little boy with brown hair pops his head out of the train along with the woman, looking at her in excitement. he then asks her: \"This is Nana's old village, isn't it?\". she nodes and embraces him joyfully."
    },
    "_meta": {
      "title": "Positive Prompt"
    }
  },
  "5233": {
    "class_type": "PrimitiveInt",
    "inputs": {
      "value": 241,
      "control_after_generate": "fixed"
    },
    "_meta": {
      "title": "length"
    }
  },
  "5223": {
    "class_type": "CreateVideo",
    "inputs": {
      "fps": [
        "5236",
        0
      ],
      "images": [
        "5261",
        0
      ],
      "audio": [
        "5261",
        1
      ]
    },
    "_meta": {
      "title": "CreateVideo"
    }
  },
  "5216": {
    "class_type": "LoraLoaderModelOnly",
    "inputs": {
      "lora_name": "ltx-2-19b-distilled-lora-384.safetensors",
      "strength_model": 0.6,
      "model": [
        "5220",
        0
      ]
    },
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "5266240": {
    "class_type": "LTXVSeparateAVLatent",
    "inputs": {
      "av_latent": [
        "5266246",
        1
      ]
    },
    "_meta": {
      "title": "LTXVSeparateAVLatent",
      "_subgraph": "5261"
    }
  },
  "5266241": {
    "class_type": "EmptyLTXVLatentVideo",
    "inputs": {
      "width": [
        "5266244",
        0
      ],
      "height": [
        "5266244",
        1
      ],
      "length": [
        "5260990",
        8
      ],
      "batch_size": 1
    },
    "_meta": {
      "title": "EmptyLTXVLatentVideo",
      "_subgraph": "5261"
    }
  },
  "5266242": {
    "class_type": "ImageScaleBy",
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 0.5,
      "image": [
        "5260990",
        7
      ]
    },
    "_meta": {
      "title": "ImageScaleBy",
      "_subgraph": "5261"
    }
  },
  "5266243": {
    "class_type": "LTXVEmptyLatentAudio",
    "inputs": {
      "audio_vae": [
        "5260990",
        6
      ],
      "frames_number": [
        "5260990",
        8
      ],
      "frame_rate": [
        "5260990",
        9
      ]
    },
    "_meta": {
      "title": "LTXVEmptyLatentAudio",
      "_subgraph": "5261"
    }
  },
  "5266244": {
    "class_type": "GetImageSize",
    "inputs": {
      "image": [
        "5266242",
        0
      ]
    },
    "_meta": {
      "title": "GetImageSize",
      "_subgraph": "5261"
    }
  },
  "5266245": {
    "class_type": "LTXVConcatAVLatent",
    "inputs": {
      "video_latent": [
        "5266241",
        0
      ],
      "audio_latent": [
        "5266243",
        0
      ]
    },
    "_meta": {
      "title": "LTXVConcatAVLatent",
      "_subgraph": "5261"
    }
  },
  "5266246": {
    "class_type": "SamplerCustomAdvanced",
    "inputs": {
      "noise": [
        "5266248",
        0
      ],
      "guider": [
        "5266247",
        0
      ],
      "sampler": [
        "5266251",
        0
      ],
      "sigmas": [
        "5266249",
        0
      ],
      "latent_image": [
        "5266250",
        0
      ]
    },
    "_meta": {
      "title": "SamplerCustomAdvanced",
      "_subgraph": "5261"
    }
  },
  "5266247": {
    "class_type": "CFGGuider",
    "inputs": {
      "cfg": 1,
      "model": [
        "5260990",
        1
      ],
      "positive": [
        "5260990",
        3
      ],
      "negative": [
        "5260990",
        4
      ]
    },
    "_meta": {
      "title": "CFGGuider",
      "_subgraph": "5261"
    }
  },
  "5266248": {
    "class_type": "RandomNoise",
    "inputs": {
      "noise_seed": 420
    },
    "_meta": {
      "title": "RandomNoise",
      "_subgraph": "5261"
    }
  },
  "5266249": {
    "class_type": "ManualSigmas",
    "inputs": {
      "sigmas": "0.909375, 0.725, 0.421875, 0.0"
    },
    "_meta": {
      "title": "ManualSigmas",
      "_subgraph": "5261"
    }
  },
  "5266250": {
    "class_type": "LTXVConcatAVLatent",
    "inputs": {
      "video_latent": [
        "5266262",
        0
      ],
      "audio_latent": [
        "5266255",
        1
      ]
    },
    "_meta": {
      "title": "LTXVConcatAVLatent",
      "_subgraph": "5261"
    }
  },
  "5266251": {
    "class_type": "KSamplerSelect",
    "inputs": {
      "sampler_name": "res_2s"
    },
    "_meta": {
      "title": "KSamplerSelect",
      "_subgraph": "5261"
    }
  },
  "5266252": {
    "class_type": "CFGGuider",
    "inputs": {
      "cfg": 4,
      "model": [
        "5260990",
        0
      ],
      "positive": [
        "5260990",
        3
      ],
      "negative": [
        "5260990",
        4
      ]
    },
    "_meta": {
      "title": "CFGGuider",
      "_subgraph": "5261"
    }
  },
  "5266253": {
    "class_type": "LTXVScheduler",
    "inputs": {
      "latent": [
        "5266245",
        0
      ]
    },
    "_meta": {
      "title": "LTXVScheduler",
      "_subgraph": "5261"
    }
  },
  "5266254": {
    "class_type": "KSamplerSelect",
    "inputs": {
      "sampler_name": "res_2s"
    },
    "_meta": {
      "title": "KSamplerSelect",
      "_subgraph": "5261"
    }
  },
  "5266255": {
    "class_type": "LTXVSeparateAVLatent",
    "inputs": {
      "av_latent": [
        "5266256",
        1
      ]
    },
    "_meta": {
      "title": "LTXVSeparateAVLatent",
      "_subgraph": "5261"
    }
  },
  "5266256": {
    "class_type": "SamplerCustomAdvanced",
    "inputs": {
      "noise": [
        "5266257",
        0
      ],
      "guider": [
        "5266252",
        0
      ],
      "sampler": [
        "5266254",
        0
      ],
      "sigmas": [
        "5266253",
        0
      ],
      "latent_image": [
        "5266245",
        0
      ]
    },
    "_meta": {
      "title": "SamplerCustomAdvanced",
      "_subgraph": "5261"
    }
  },
  "5266258": {
    "class_type": "LTXVSpatioTemporalTiledVAEDecode",
    "inputs": {
      "tile_x": 4,
      "tile_y": 4,
      "tile_t": 16,
      "overlap_x": 4,
      "overlap_y": false,
      "overlap_t": "auto",
      "vae": [
        "5260990",
        5
      ],
      "latents": [
        "5266240",
        0
      ]
    },
    "_meta": {
      "title": "LTXVSpatioTemporalTiledVAEDecode",
      "_subgraph": "5261"
    }
  },
  "5266259": {
    "class_type": "LTXVAudioVAEDecode",
    "inputs": {
      "samples": [
        "5266240",
        1
      ],
      "audio_vae": [
        "5260990",
        6
      ]
    },
    "_meta": {
      "title": "LTXVAudioVAEDecode",
      "_subgraph": "5261"
    }
  },
  "5266257": {
    "class_type": "RandomNoise",
    "inputs": {
      "noise_seed": [
        "5260990",
        10
      ]
    },
    "_meta": {
      "title": "RandomNoise",
      "_subgraph": "5261"
    }
  },
  "5266262": {
    "class_type": "LTXVLatentUpsampler",
    "inputs": {
      "samples": [
        "5266255",
        0
      ],
      "upscale_model": [
        "5260990",
        2
      ],
      "vae": [
        "5260990",
        5
      ]
    },
    "_meta": {
      "title": "LTXVLatentUpsampler",
      "_subgraph": "5261"
    }
  },
  "5266263": {
    "class_type": "MarkdownNote",
    "inputs": {},
    "_meta": {
      "title": "Sampler",
      "_subgraph": "5261"
    }
  },
  "5266264": {
    "class_type": "MarkdownNote",
    "inputs": {},
    "_meta": {
      "title": "Sampler",
      "_subgraph": "5261"
    }
  },
  "5272": {
    "class_type": "MarkdownNote",
    "inputs": {},
    "_meta": {
      "title": "Prompting LTX-2"
    }
  },
  "5275": {
    "class_type": "MarkdownNote",
    "inputs": {},
    "_meta": {
      "title": "Model Links"
    }
  },
  "5218": {
    "class_type": "LTXVGemmaCLIPModelLoader",
    "inputs": {
      "clip_name": "gemma-3-12b-it-qat-q4_0-unquantized/model-00001-of-00005.safetensors",
      "vae_name": "ltx-2-19b-dev.safetensors",
      "max_sequence_length": 1024
    },
    "_meta": {
      "title": "LTXVGemmaCLIPModelLoader"
    }
  }
}